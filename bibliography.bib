@article{b:Pegasus,
title = {Pegasus, a workflow management system for science automation},
journal = {Future Generation Computer Systems},
volume = {46},
pages = {17-35},
year = {2015},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2014.10.008},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X14002015},
author = {Ewa Deelman and Karan Vahi and Gideon Juve and Mats Rynge and Scott Callaghan and Philip J. Maechling and Rajiv Mayani and Weiwei Chen and Rafael {Ferreira da Silva} and Miron Livny and Kent Wenger},
keywords = {Scientific workflows, Workflow management system, Pegasus},
abstract = {Modern science often requires the execution of large-scale, multi-stage simulation and data analysis pipelines to enable the study of complex systems. The amount of computation and data involved in these pipelines requires scalable workflow management systems that are able to reliably and efficiently coordinate and automate data movement and task execution on distributed computational resources: campus clusters, national cyberinfrastructures, and commercial and academic clouds. This paper describes the design, development and evolution of the Pegasus Workflow Management System, which maps abstract workflow descriptions onto distributed computing infrastructures. Pegasus has been used for more than twelve years by scientists in a wide variety of domains, including astronomy, seismology, bioinformatics, physics and others. This paper provides an integrated view of the Pegasus system, showing its capabilities that have been developed over time in response to application needs and to the evolution of the scientific computing platforms. The paper describes how Pegasus achieves reliable, scalable workflow execution across a wide variety of computing infrastructures.}
}

@article{b:Hyperflow,
title = "HyperFlow: A model of computation, programming approach and enactment engine for complex distributed workflows",
journal = "Future Generation Computer Systems",
volume = "55",
pages = "147 - 162",
year = "2016",
issn = "0167-739X",
doi = "10.1016/j.future.2015.08.015",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X15002770",
author = "Bartosz Balis",
keywords = "Scientific workflows, Process networks, Workflow programming, Workflow patterns, Workflow enactment",
abstract = "This paper presents HyperFlow: a model of computation, programming approach and enactment engine for scientific workflows. Workflow programming in HyperFlow combines a simple declarative description of the workflow structure with low-level implementation of workflow activities in a mainstream scripting language. The aim of this approach is to increase the programming productivity of workflow developers who are skilled programmers and desire a programming experience similar to the one offered by a mature programming ecosystem. Combining a declarative description with low-level programming enables elimination of shim nodes from the workflow graph, considerably simplifying workflow implementations. The workflow description is based on a formal model of computation (Process Networks) and is characterized by a simple and concise syntax, utilizing just three key abstractions—processes, signals and functions. Yet it is sufficient for expressing complex workflow patterns in a simple way. The adopted model of computation implemented in the HyperFlow workflow engine enables fully distributed and decentralized workflow enactment. The paper describes HyperFlow from the perspective of its workflow programming capabilities, the adopted model of computation, as well as the enactment engine, in particular its distributed workflow enactment capability. The provenance model and logging features are also presented. Several workflow examples derived from other workflow systems and reimplemented in HyperFlow are extensively discussed."
}

@article{b:Tetris,
author = {Grandl, Robert and Ananthanarayanan, Ganesh and Kandula, Srikanth and Rao, Sriram and Akella, Aditya},
title = {Multi-Resource Packing for Cluster Schedulers},
year = {2014},
issue_date = {October 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {4},
issn = {0146-4833},
url = {https://doi.org/10.1145/2740070.2626334},
doi = {10.1145/2740070.2626334},
abstract = {Tasks in modern data parallel clusters have highly diverse resource requirements, along CPU, memory, disk and network. Any of these resources may become bottlenecks and hence, the likelihood of wasting resources due to fragmentation is now larger. Today's schedulers do not explicitly reduce fragmentation. Worse, since they only allocate cores and memory, the resources that they ignore (disk and network) can be over-allocated leading to interference, failures and hogging of cores or memory that could have been used by other tasks. We present Tetris, a cluster scheduler that packs, i.e., matches multi-resource task requirements with resource availabilities of machines so as to increase cluster efficiency (makespan). Further, Tetris uses an analog of shortest-running-time-first to trade-off cluster efficiency for speeding up individual jobs. Tetris' packing heuristics seamlessly work alongside a large class of fairness policies. Trace-driven simulations and deployment of our prototype on a 250 node cluster shows median gains of 30% in job completion time while achieving nearly perfect fairness.},
journal = {SIGCOMM Comput. Commun. Rev.},
month = aug,
pages = {455–466},
numpages = {12},
keywords = {cluster schedulers, packing, makespan, multi-dimensional, fairness, completion time}
}

@article{b:HEFT,
author = {Topcuoglu, Haluk and Hariri, Salim and Wu, Min-You},
year = {2002},
month = {04},
pages = {260-274},
title = {Performance-effective and low-complexity task scheduling forheterogeneous computing},
volume = {13},
journal = {Parallel and Distributed Systems, IEEE Transactions on},
doi = {10.1109/71.993206}
}

@article{b:PEFT,
  author={H. {Arabnejad} and J. G. {Barbosa}},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={List Scheduling Algorithm for Heterogeneous Systems by an Optimistic Cost Table}, 
  year={2014},
  volume={25},
  number={3},
  pages={682-694},
  doi={10.1109/TPDS.2013.57}
}

@article{b:Task-Clustering-Hybrid-Algorithm,
author = {Kaur, Avinash and Gupta, Pooja and Singh, Manpreet},
year = {2019},
month = {05},
pages = {237-258},
title = {Hybrid Balanced Task Clustering Algorithm for Scientific Workflows in Cloud Computing},
volume = {20},
journal = {Scalable Computing: Practice and Experience},
doi = {10.12694/scpe.v20i2.1515}
}

@article{b:Montage,
author = {Katz, Daniel S. and Berriman, G. and Good, John and Laity, Anastasia and Deelman, Ewa and Kesselman, Carl and Singh, Gurmeet and Su, Mei-Hui and Prince, Thomas and Williams, Roy},
year = {2010},
month = {05},
pages = {},
title = {Montage: A grid portal and software toolkit for science-grade astronomical image mosaicking},
volume = {4},
journal = {International Journal of Computational Science and Engineering},
doi = {10.1504/IJCSE.2009.026999}
}

@article{b:Performance-Analysis-Scheduling-DAG,
author = {Ahmad, Wakar and Alam, Bashir and Malik, Sahil},
year = {2019},
month = {01},
pages = {},
title = {Performance Analysis of List Scheduling Algorithms by Random Synthetic DAGs},
journal = {SSRN Electronic Journal},
doi = {10.2139/ssrn.3349016}
}

@article{b:SoyKB-PGen,
author = {Liu, Yang and Khan, Saad and Wang, Juexin and Rynge, Mats and Zhang, Yuanxun and Zeng, Shuai and Chen, Shiyuan and Maldonado dos Santos, Joao Vitor and Valliyodan, Babu and Calyam, Prasad and Merchant, Nirav and Nguyen, Henry and Xu, Dong and Joshi, Trupti},
year = {2016},
month = {10},
pages = {337},
title = {PGen: Large-scale genomic variations analysis workflow and browser in SoyKB},
volume = {17},
journal = {BMC Bioinformatics},
doi = {10.1186/s12859-016-1227-y}
}



@inproceedings{b:Borg,
title	= {Large-scale cluster management at {Google} with {Borg}},
author	= {Abhishek Verma and Luis Pedrosa and Madhukar R. Korupolu and David Oppenheimer and Eric Tune and John Wilkes},
year	= {2015},
booktitle	= {Proceedings of the European Conference on Computer Systems (EuroSys)},
address	= {Bordeaux, France}
}

@inproceedings{b:Magellan,
author = {Ramakrishnan, Lavanya and Zbiegel, Piotr T. and Campbell, Scott and Bradshaw, Rick and Canon, Richard Shane and Coghlan, Susan and Sakrejda, Iwona and Desai, Narayan and Declerck, Tina and Liu, Anping},
title = {Magellan: Experiences from a Science Cloud},
year = {2011},
isbn = {9781450306997},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1996109.1996119},
doi = {10.1145/1996109.1996119},
abstract = {Cloud resources promise to be an avenue to address new categories of scientific applications including data-intensive science applications, on-demand/surge computing, and applications that require customized software environments. However, there is a limited understanding on how to operate and use clouds for scientific applications. Magellan, a project funded through the Department of Energy's (DOE) Advanced Scientific Computing Research (ASCR) program, is investigating the use of cloud computing for science at the Argonne Leadership Computing Facility (ALCF) and the National Energy Research Scientific Computing Facility (NERSC). In this paper, we detail the experiences to date at both sites and identify the gaps and open challenges from both a resource provider as well as application perspective.},
booktitle = {Proceedings of the 2nd International Workshop on Scientific Cloud Computing},
pages = {49–58},
numpages = {10},
keywords = {programming model, cloud computing, virtual machines, mapreduce, science},
location = {San Jose, California, USA},
series = {ScienceCloud '11}
}

@inproceedings{b:Enable-HPC-Cloud-K8s,
  author={Beltre, Angel M. and Saha, Pankaj and Govindaraju, Madhusudhan and Younge, Andrew and Grant, Ryan E.},
  booktitle={2019 IEEE/ACM International Workshop on Containers and New Orchestration Paradigms for Isolated Environments in HPC (CANOPIE-HPC)}, 
  title={Enabling HPC Workloads on Cloud Infrastructure Using Kubernetes Container Orchestration Mechanisms}, 
  year={2019},
  volume={},
  number={},
  pages={11-20},
  doi={10.1109/CANOPIE-HPC49598.2019.00007}
}

@inproceedings {b:Graphene,
author = {Robert Grandl and Srikanth Kandula and Sriram Rao and Aditya Akella and Janardhan Kulkarni},
title = {{GRAPHENE}: Packing and Dependency-Aware Scheduling for Data-Parallel Clusters},
booktitle = {12th {USENIX} Symposium on Operating Systems Design and Implementation ({OSDI} 16)},
year = {2016},
isbn = {978-1-931971-33-1},
address = {Savannah, GA},
pages = {81--97},
url = {https://www.usenix.org/conference/osdi16/technical-sessions/presentation/grandl_graphene},
publisher = {{USENIX} Association},
month = nov,
}

@inproceedings{b:Grid-Workflow-Scheduling-Strategies,
author = {Wieczorek, Marek and Prodan, Radu and Fahringer, Thomas},
title = {Comparison of Workflow Scheduling Strategies on the Grid},
year = {2005},
isbn = {3540341412},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11752578_95},
doi = {10.1007/11752578_95},
abstract = {Scheduling is a key concern for the execution of performance-driven Grid applications. In this paper we comparatively examine different existing approaches for scheduling of scientific workflow applications in a Grid environment. We evaluate three algorithms namely genetic, HEFT, and simple “myopic” and compare incremental workflow partitioning against the full-graph scheduling strategy. We demonstrate experiments using real-world scientific applications covering both balanced (symmetric) and unbalanced (asymmetric) workflows. Our results demonstrate that full-graph scheduling with the HEFT algorithm performs best compared to the other strategies examined in this paper.},
booktitle = {Proceedings of the 6th International Conference on Parallel Processing and Applied Mathematics},
pages = {792–800},
numpages = {9},
location = {Pozna\'{n}, Poland},
series = {PPAM'05}
}

@inproceedings{b:Task-Clustering-Pegasus,
author = {Singh, Gurmeet and Su, Mei-Hui and Vahi, Karan and Deelman, Ewa and Berriman, Bruce and Good, John and Katz, Daniel S. and Mehta, Gaurang},
title = {Workflow Task Clustering for Best Effort Systems with Pegasus},
year = {2008},
isbn = {9781595938350},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1341811.1341822},
doi = {10.1145/1341811.1341822},
abstract = {Many scientific workflows are composed of fine computational granularity tasks, yet they are composed of thousands of them and are data intensive in nature, thus requiring resources such as the TeraGrid to execute efficiently. In order to improve the performance of such applications, we often employ task clustering techniques to increase the computational granularity of workflow tasks. The goal is to minimize the completion time of the workflow by reducing the impact of queue wait times. In this paper, we examine the performance impact of the clustering techniques using the Pegasus workflow management system. Experiments performed using an astronomy workflow on the NCSA TeraGrid cluster show that clustering can achieve a significant reduction in the workflow completion time (up to 97%).},
booktitle = {Proceedings of the 15th ACM Mardi Gras Conference: From Lightweight Mash-Ups to Lambda Grids: Understanding the Spectrum of Distributed Computing Requirements, Applications, Tools, Infrastructures, Interoperability, and the Incremental Adoption of Key Capabilities},
articleno = {9},
numpages = {8},
keywords = {best effort systems, workflow clustering, queue wait time, task clustering},
location = {Baton Rouge, Louisiana, USA},
series = {MG '08}
}

@inproceedings{b:Skyport,
  author={Gerlach, Wolfgang and Tang, Wei and Keegan, Kevin and Harrison, Travis and Wilke, Andreas and Bischof, Jared and D'Souza, Mark and Devoid, Scott and Murphy-Olson, Daniel and Desai, Narayan and Meyer, Folker},
  booktitle={2014 5th International Workshop on Data-Intensive Computing in the Clouds}, 
  title={Skyport - Container-Based Execution Environment Management for Multi-cloud Scientific Workflows}, 
  year={2014},
  volume={},
  number={},
  pages={25-32},
  doi={10.1109/DataCloud.2014.6}
}

@inproceedings{b:Dynamic-Scheduling-Case-Study,
author = {Prodan, Radu and Fahringer, Thomas},
title = {Dynamic Scheduling of Scientific Workflow Applications on the Grid: A Case Study},
year = {2005},
isbn = {1581139640},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1066677.1066835},
doi = {10.1145/1066677.1066835},
abstract = {The existing Grid workflow scheduling projects do not handle recursive loops which
are characteristic to many scientific problems. We propose a hybrid approach for scheduling
Directed Graph (DG)-based workflows in a Grid environment with dynamically changing
computational and network resources. Our dynamic scheduling algorithm is based on
the iterative invocation of classical static Directed Acyclic Graphs (DAGs) scheduling
heuristics generated using well-defined cycle elimination and task migration techniques.
We approach the static scheduling problem as an application of a modular optimisation
tool using genetic algorithms. We report successful implementation and experimental
results on a pilot real-world material science workflow application.},
booktitle = {Proceedings of the 2005 ACM Symposium on Applied Computing},
pages = {687–694},
numpages = {8},
keywords = {scheduling, genetic algorithms, scientific workflows, optimisation, grid computing, performance steering},
location = {Santa Fe, New Mexico},
series = {SAC '05}
}

@inproceedings{b:Performance-Comparison-Scheduling-DAG,
author = {Maurya, Ashish Kumar and Tripathi, Anil Kumar},
title = {Performance Comparison of HEFT, Lookahead, CEFT and PEFT Scheduling Algorithms for Heterogeneous Computing Systems},
year = {2017},
isbn = {9781450353243},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3154979.3154985},
doi = {10.1145/3154979.3154985},
abstract = {Efficient scheduling algorithms play an essential part in heterogeneous computing systems to achieve high performance. The problem of producing an optimal schedule for the precedence-constrained tasks is recognized to be an NP-complete problem. To work out this problem, the researchers have already been proposed various scheduling algorithms in the literature. This paper discusses four well-known list scheduling algorithms such as HEFT, Lookahead, CEFT and PEFT for heterogeneous computing systems and performs experiments for randomly created application graphs and the application graphs generated from real-world problem for instance molecular dynamic code. The performance of algorithms are evaluated and compared on different scheduling parameters such as scheduling length ratio, efficiency, etc.},
booktitle = {Proceedings of the 7th International Conference on Computer and Communication Technology},
pages = {128–132},
numpages = {5},
keywords = {Heterogeneous Computing Systems, DAG Scheduling, Lookahead, CEFT, HEFT, PEFT},
location = {Allahabad, India},
series = {ICCCT-2017}
}



@misc{b:Kubernetes-what-is,
  title = {Kubernetes - What is Kubernetes?},
  howpublished = {\url{https://kubernetes.io/docs/concepts/overview/what-is-kubernetes/}},
  note = {Accessed: 2020-11-03},
  key = {Kubernetes - what is}
}

@misc{b:Kubernetes-scheduler,
  title = {Kubernetes - Kubernetes Scheduler},
  howpublished = {\url{https://kubernetes.io/docs/concepts/scheduling-eviction/kube-scheduler/}},
  note = {Accessed: 2020-11-03},
  key = {Kubernetes - Kubernetes Scheduler}
}

@misc{b:Borg-K8s-predecessor,
  title = {Kubernetes - Borg: The predecessor to Kubernetes},
  howpublished = {\url{https://kubernetes.io/blog/2015/04/borg-predecessor-to-kubernetes/}},
  note = {Accessed: 2020-11-03},
  key = {Kubernetes - Borg}
}

@misc{b:AWS-EKS,
  title = {Amazon EKS - Managed Kubernetes Service},
  howpublished = {\url{https://aws.amazon.com/eks/}},
  note = {Accessed: 2021-05-07},
  key = {Elastic Kubernetes Service}
}

@misc{b:IBM-CaaS,
  title = {IBM - What is Containers as a Service?},
  howpublished = {\url{https://www.ibm.com/services/cloud/containers-as-a-service/}},
  note = {Accessed: 2021-05-07},
  key = {Containers as a Service}
}

@misc{b:Montage-url,
  title = {Montage - An astronomical image engine},
  howpublished = {\url{http://montage.ipac.caltech.edu/}},
  note = {Accessed: 2021-05-11},
  key = {Montage - An astronomical image engine}
}

@misc{b:SoyKB-workflow-url,
  title = {SoyKB -Soybean Knowledge Base - Workflow},
  howpublished = {\url{http://soykb.org/Pegasus/}},
  note = {Accessed: 2021-05-13},
  key = {SoyKB - Workflow}
}

@misc{b:Hyperflow-k8s-deployment,
  title = {Hyperflow - Kubernetes deployment},
  howpublished = {\url{https://github.com/hyperflow-wms/hyperflow-k8s-deployment/}},
  note = {Accessed: 2021-05-13},
  key = {Hyperflow - Kubernetes deployment}
}



@inbook{b:Cloud-Principles-Paradigms,
author = {Buyya, Rajkumar and Broberg, James and Goscinski, Andrzej M.},
title = {Cloud Computing Principles and Paradigms},
year = {2011},
chapter = {1},
pages = {3-37},
isbn = {9780470887998},
publisher = {Wiley Publishing},
abstract = {The primary purpose of this book is to capture the state-of-the-art in Cloud Computing technologies and applications. The book will also aim to identify potential research directions and technologies that will facilitate creation a global market-place of cloud computing services supporting scientific, industrial, business, and consumer applications. We expect the book to serve as a reference for larger audience such as systems architects, practitioners, developers, new researchers and graduate level students. This area of research is relatively recent, and as such has no existing reference book that addresses it.This book will be a timely contribution to a field that is gaining considerable research interest, momentum, and is expected to be of increasing interest to commercial developers. The book is targeted for professional computer science developers and graduate students especially at Masters level. As Cloud Computing is recognized as one of the top five emerging technologies that will have a major impact on the quality of science and society over the next 20 years, its knowledge will help position our readers at the forefront of the field.}
}
